---
title: 'Deep Learning Project'
author: "Ilia Azizi, Alexandre Schroeter"
date: "`r format(Sys.time(), '%d %B, %Y')`"   
output:
  html_document:
    theme: cerulean
    highlight: textmate
    toc: true
    toc_float: true
    depth: 1
bibliography: ref.bibtex
biblio-style: "apalike"
link-citations: true
---
<style type="text/css">

body{ /* Normal  */
      font-size: 18px;
  }
  
h1.title {
  font-size: 40px;
  text-align: center
}

.pad {
    padding-top: 200px; 
}

</style>


<style>
table th:first-of-type {
    width: 40%;
}
table th:nth-of-type(2) {
    width: 20%;
}
table th:nth-of-type(3) {
    width: 5%;
}
table th:nth-of-type(4) {
    width: 15%;
}
table th:nth-of-type(5) {
    width: 20%;
}

</style>

```{r, include = F}
library(keras)
library(cloudml)
library(tfruns)
library(kerasR)
library(caret)
library(here)
library(scales)
```
## <strong>Introduction</strong>

The words "COVID-19 pandemic" and "SARS-CoV-2 virus" have become household names over the past 6 months. Despite its recent discovery, the virus has had a tremendous impact on our lives. As of today, no vaccine or effective treatment has been discovered. While the “Great Lockdown” transitions away from many western nations, the battle against the pandemic has not yet rested. Thus far, two sets of measures have been decisive in combatting the virus. The first set of enforced policies impose a burden on the citizens to follow basic hygiene practices henceforth limiting the further spread of the virus. The execution of the second set of measures concerns the governmental bodies, where they are required to effectively detect, diagnose and track every infected citizen. The latter set of policies call for more practical methods of detection, given the constrained resources of the medical systems.

At the time writing, different types of tests have been executed. The first kind of test which accounts for a vast majority of examinations is called **polymerise chain reaction (PCR) testing**. The method searches for the viral RNA and is only capable of diagnosis when the patient has been actively infected. The test is performed using a nasopharyngeal swab. The aforementioned procedure, which is a very labour intensive one, results in human errors and incorrect diagnosis. False negatives can be as high as 30%.

The second category of tests is called **serologic testing**. This kind of test does not specifically search for the virus RNA but the antibodies to COVID-19. The test is carried by using a blood sample. Antibodies are produced by the body when an infection with a specific virus takes place. The antibodies are generally produced one or two weeks after infection and are useful to assess who has been in contact with the virus. This kind of test is less suitable to detect the infection early and are particularly interesting for the epidemiologists who want to build a clearer picture of the general sanitary conditions. The result produced from this test only displays who has been infected, but it does not determine if and for how long immunity has been acquired for this virus.

Other tests are under development, notably, lateral flow assays which look for a biological marker in different samples (urine, blood, saliva,etc.). It works just like a pregnancy test and can be used for in-home testing. Other pharmaceuticals are developing **rapid in-clinic antigen testing**. In this procedure, the analyzing device uses cartridges where the biological components in each cartridge are used to prove if the patient has SARS-CoV-2 or any of 9 other respiratory diseases.

Depending on the test type and where it is performed, the prices can be high. Furthermore, reagents (2020) are also key components of most tests and are currently in short supply. China and the US are producers and exporters of reagents but both countries have been hit by the pandemic.

In short, tests are in great demand.

Up to now, only a fraction of the population has been tested, and even if testing every person may be useless, having have the capabilities to do so is critical.

```{r, echo=FALSE, out.width = '100%', message = F, fig.cap = "Number of tests per thousand -@data_2020"}
library(here)
knitr::include_graphics(here("images/tests.png"))
```

Even small countries like Iceland or Luxembourg have only been able to carry 100 tests per thousand inhabitants. 

SARS-CoV-2 transmission is difficult to trace as the symptoms can appear as long as 14 days after exposure to the virus. The most symptomatic people have fever, tiredness and a dry cough, among other things. People are very susceptible to developing pneumonia. 

Another method used to confirm a diagnosis is the use of chest x-rays to detect the virus. 

However, this method also has both advantages and drawbacks. First, it can be carried in almost every country because the material to conduct the test is ubiquitous. Second, it is less costly than a CT scan or PCR test, and most of the time, CT scans can only be carried at bigger hospitals. Finally, X-rays can be conducted more safely than the nasal swab method as they do not risk aerosolizing the virus when the test is conducted. 

The drawbacks of using X-ray scans include the increased difficulty of detecting asymptomatic cases, lack of its remoteness and the availability of a radiologist to analyze and determine the outcome of the X-ray scans.

No method alone will be perfect to detect the virus and implementation of multiple test techniques at once may be needed. For example, it could be interesting to use X-rays primarily to determine if one is COVID positive so that PCR tests may be allocated elsewhere, where X-rays cannot be used. 

Therefore, having a cheap, fast and reliable method such as X-rays is deemed suitable by the authors however this calls for automation of the diagnostic process by analyzing the scans and determining if the disease exists or not -@hemdan2020covidxnet. (_it is not advised to use this technique without the approval of a medical practioner._)

## <strong>Research question</strong>
Thus, our research question is 

> **Can Deep Learning be used to rapidly and accurately analyze X-rays pictures to predict COVID-19 ?**

## <strong>Previous approaches </strong>
| Study               | Type of images | Number of cases                                       | Method used            | Accuracy (%) |
|---------------------|----------------|-------------------------------------------------------|------------------------|--------------|
| **Ioannis et al.** -@Apostolopoulos_2020  | Chest X-ray    | 224 COVID-19(+)<br> 700 Pneumonia<br> 504 healthy     | VGG-19                 | 93.48        |
| **Wang and Wong** -@wang2020covidnet   | Chest X-ray    | 53 COVID-19(+)<br> 5526 COVID-19(-)<br> 8066 Healthy  | COVID-NET              | 92.4         |
| **Sethy and Behra** -@articlesethy | Chest X-ray    | 25 COVID-19(+)<br> 25 COVID-19(-)                     | ResNet50+<br> SVM      | 95.38        |
| **Hemdan et al.** -@hemdan2020covidxnet  | Chest X-ray    | 25 COVID-19(+)<br> 25 Normal                          | COVIDX-Net             | 90.0         |
| **Narin et al.** -@narin2020automatic   | Chest X-ray    | 50 COVID-19(+)<br> 50 COVID-19(-)                     | Deep CNN<br> ResNet-50 | 98.0         |
| **Ozturk et al.**  -@ozturk2020automated | Chest X-ray    | 125 COVID-19(+)<br> 500 No-Findings                   | DarkCovidNet           | 98.08        |
| **Ozturk et al.**-@ozturk2020automated  | Chest X-ray    | 125 COVID-19(+)<br> 500 Pneumonia<br> 500 No-Findings | DarkCovidNet           | 87.02        |

The traditional approach consists of using Convolutional Neural Networks(CNN) to solve this task. 
Half of the previous approaches use transfer learning for the purpose. VGG_19 and ResNet50 are the pre-trained networks of preference. Sethy and Behra use a Support Vector Machine on top of their CNN, at the very end of the dense layers in place of the traditional softmax activation function. 

The other half of the approaches use customized networks such as the COVIDX-Net or the DarkCovidNet whose architecture is based on the DarkNet model. The DarkNet model is a model available on MATLAB which is 19 layers deep.


## <strong>Data</strong>
As SARS-CoV-2 is a new virus, most X-rays available come from different sources. At the time being, 5 of them are worth mentionning:

a.<a href="https://cases.rsna.org/coronavirus/"> The Radiological Society of North America (RSNA)</a> <br>
b. <a href=" https://radiopaedia.org/search?utf8=%E2%9C%93&q=covid&scope=all&lang=us/"> Radiopaedia</a><br>
c. <a href="https://www.sirm.org/en/category/articles/covid-19-database/">The Italian Society of Medical and Interventional Radiology (SIRM)</a><br>
d. <a href="https://www.eurorad.org/"> Eurorad.</a><br>
e. <a href="https://coronacases.org/forum/coronacases-org-helping-radiologists-to-help-people-in-more-than-100-countries-1"> Coronacases.org</a>

As most of the data is not centralized, and therefore not always reliable, one of the leading repositories on COVID-19 positive (pneumonia) X-rays is the [covid-chestxray-dataset.](https://github.com/ieee8023/covid-chestxray-dataset) Using this repository, the data can be downloaded freely. 
This repo is approved by the University of Montreal's Ethics Committee and is being continuously updated. Furthermore, previous studies have already used this repo. We sample 140 pictures of it.This has been placed in our data folder inside a sub-folder labeled *chestxray_COVID*. A small analysis and selection of this dataset can be found in the scripts/import+storage under the *photo-organization* script. Also please note that we have used one angle of chest X-rays from this repo called **anteroposterior(AP)** which is the most frequent class of chest X-ray scans. We have ignored other forms of scans which include but are not limited posteroanterior and lateral scans.

To find COVID-19 negative pictures as well as general bacterial and viral pneumonia, we have used another dataset provided by a study done @-Kermany et al. which can be found [here](https://data.mendeley.com/datasets/rscbjbr9sj/3). This has been placed in our data folder inside a sub-folder labeled *Kermany_OTHERS*. This scans have the same AP view as the first dataset.

As the number of images of COVID+ at our disposal, if fairly limited, we build a train set, a small test set and a large test set. This will be specified below. 

**The total size of the data 1.28GB with 5893 items. **


## <strong>Methodology</strong>

## CNN models{.tabset .tabset-fade}
2 questions which naturally arise as we conduct our experiments are: 

* Can we accurately identify COVID+ individuals from COVID- individuals (binary classification task) ? 
* Can we accurately identify COVID+ individuals from COVID- individuals from individuals who have a viral pneumonia other than COVID from individuals who have a bacterial pneumonia (multiclass classification task with 4 outcome classes) ?

From the literature, we decide to use 2 different models, other than the ones which have been used so far. We decide to use transfer learning for our tasks. We train and test 2 CNN pretrained networks per task and use them as a basis for our model. We then add dense layers on top of them. 

* **VGG16**: this pretrained model built on the ImageNet dataset has a size of 528MB a Top-1 accuracy of 0.713. It is 23-layer deep and has 138 Mio parameters making it a very large model.


* **DenseNet201**: this pretrained model built on the ImageNet dataset has a size of 80MB a Top-1 accuracy of 0.773. It is 201-layer deep and has 20 Mio parameters. 

Both models are thus very different in size and in depth. 

&nbsp;
&nbsp;
&nbsp;

We select our best models based on the categorical accuracy as a first metric and the validation loss if there is a tie in categorical accuracy. 

**Binary classification**
&nbsp;

We use the 140 COVID+ images as well as 140 COVID- images, so 280 images in total. We use 80% (224 images) of these as a training set and 20% (56 images) as a testing set. 50% of the training set will build the validation set. We tune our models on Google Cloud.
&nbsp;
To challenge our model, we also build a larger test set made of 29 COVID+ and 1573 COVID- images

<center>
<html>
<body >
<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-i7a5{font-family:Verdana, Geneva, sans-serif !important;;font-size:14px;text-align:left;vertical-align:top}
.tg .tg-5x9q{font-family:Verdana, Geneva, sans-serif !important;;font-size:14px;font-weight:bold;text-align:left;vertical-align:top}
.tg .tg-3zvv{font-family:Verdana, Geneva, sans-serif !important;;font-size:14px;text-align:center;vertical-align:top}
</style>
<table class="tg" width = 50%>
<thead>
  <tr>
    <th class="tg-i7a5"; width = 20%></th>
    <th class="tg-5x9q"; width = 15%>COVID+</th>
    <th class="tg-5x9q"; width = 15%>COVID-</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-i7a5">Train set</td>
    <td class="tg-3zvv">112</td>
    <td class="tg-3zvv">112</td>
  </tr>
  <tr>
    <td class="tg-i7a5">Small test set</td>
    <td class="tg-3zvv">28</td>
    <td class="tg-3zvv">28</td>
  </tr>
  <tr>
    <td class="tg-i7a5">Large test set</td>
    <td class="tg-3zvv">28</td>
    <td class="tg-3zvv">1572</td>
  </tr>
</tbody>
</table>

</body>
</html>
</center>

&nbsp;
&nbsp;
&nbsp;

**Multiclass classification**

Again, we build one training set and two testing sets; a small one and a large one. The table below indicates how many images were used per class and per set. 

<center>
<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-i7a5{font-family:Verdana, Geneva, sans-serif !important;;font-size:14px;text-align:left;vertical-align:top}
.tg .tg-5x9q{font-family:Verdana, Geneva, sans-serif !important;;font-size:14px;font-weight:bold;text-align:left;vertical-align:top}
.tg .tg-3zvv{font-family:Verdana, Geneva, sans-serif !important;;font-size:14px;text-align:center;vertical-align:top}
</style>
<table class="tg" width = 80%>
<thead>
  <tr>
    <th class="tg-i7a5"; width = 20%></th>
    <th class="tg-5x9q"; width = 10%>COVID+</th>
    <th class="tg-5x9q"; width = 10%>COVID-</th>
    <th class="tg-5x9q"; width = 10%>Viral Pneumonia</th>
    <th class="tg-5x9q"; width = 10%>Bacterial Pneumonia</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-i7a5">Train set</td>
    <td class="tg-3zvv">112</td>
    <td class="tg-3zvv">112</td>
    <td class="tg-3zvv">112</td>
    <td class="tg-3zvv">112</td>
  </tr>
  <tr>
    <td class="tg-i7a5">Small test set</td>
    <td class="tg-3zvv">28</td>
    <td class="tg-3zvv">28</td>
    <td class="tg-3zvv">28</td>
    <td class="tg-3zvv">28</td>
  </tr>
  <tr>
    <td class="tg-i7a5">Large test set</td>
    <td class="tg-3zvv">28</td>
    <td class="tg-3zvv">1583</td>
    <td class="tg-3zvv">1494</td>
    <td class="tg-3zvv">2788</td>
  </tr>
</tbody>
</table>
</center>

&nbsp;
&nbsp;



### Binary VGG16
Structure of the model :

* VGG16 base
* 2 hidden layers with 100 and 50 nodes respectively
* Final layer with 2 nodes and the softmax activation function
* SeLU activation function in each hidden layer
* Dropout rate of 0.2
* $l_1$ regularization penalty of 0.001
* Adamax optimizer with a learning rate of 0.001


We train this model for 30 epochs and we use early stopping with patience = 7. 
&nbsp;
```{r, include = F, results = "hide"}
#load model

generator_test <-
  image_data_generator(
    rescale = 1 / 255
  )
test_binary <- flow_images_from_directory(
  #directory = gs_data_dir_local("gs://covid-pw2/final_data/binary/test"),
  directory = here::here("data/final_data/binary/test"),
  target_size = c(224, 224),
  generator = generator_test,
  batch_size = 8
)

large_test_binary <- flow_images_from_directory(
  #directory = gs_data_dir_local("gs://covid-pw2/final_data/binary/test"),
  directory = here::here("data/binary_large_test"),
  target_size = c(224, 224),
  generator = generator_test,
  batch_size = 8
)


test_mc <- flow_images_from_directory(
  #directory = gs_data_dir_local("gs://covid-pw2/final_data/binary/test"),
  directory = here::here("data/final_data/multiclass/test"),
  target_size = c(224, 224),
  generator = generator_test,
  batch_size = 8
)

large_test_mc <- flow_images_from_directory(
  #directory = gs_data_dir_local("gs://covid-pw2/final_data/binary/test"),
  directory = here::here("data/multiclass_large_test"),
  target_size = c(224, 224),
  generator = generator_test,
  batch_size = 8
)


```
&nbsp;
```{r, echo = F, fig.align="center"}
vgg16_binary <- load_model_hdf5(here::here("best_models/vgg16_binary/best_second_vgg16_binary.h5"))
```


```{r, echo = F, fig.align="center"}
#load model
summary(vgg16_binary)
```
&nbsp;
&nbsp;

**Small test set**
```{r, echo = F, fig.align="center"}
#load model

b16s <- vgg16_binary %>% evaluate_generator(generator = test_binary, steps = test_binary$n / test_binary$batch_size)

print(b16s)


# predicted <- vgg16_binary %>% predict_generator(generator = test, steps = test$batch_size / test$n)
# predicted_tr <- (apply(predicted, MARGIN = 1, which.max)-1) %>% as.factor()
# 
# observed <- test$classes %>% as.factor()
# caret::confusionMatrix(predicted_tr, observed)
# 
# table(predicted_tr, observed)
```
Based on our small test set, we can predict COVID patients in  `r label_percent(accuracy = 4)(round(b16s$categorical_accuracy,4))` of the cases.
&nbsp;
&nbsp;
&nbsp;
&nbsp;

**Large test set**
```{r, echo = F, fig.align="center"}
#load model
b16l <- vgg16_binary %>% evaluate_generator(generator = large_test_binary, steps = large_test_binary$n / large_test_binary$batch_size)

print(b16l)


```
When we test our model on the large dataset, the accuracy reaches `r label_percent(accuracy = 4)(round(b16l$categorical_accuracy,4))`.  

&nbsp;

### Binary DenseNet201
Structure of the model :

* DenseNet201 base
* 2 hidden layers with 100 and 100 nodes respectively
* Final layer with 2 nodes and the softmax activation function
* ReLU activation function in each hidden layer
* Dropout rate of 0.2
* No $l_1$ regularization penalty
* Adamax optimizer with a learning rate of 0.001

We train this model for 30 epochs and we use early stopping with patience = 7. 

```{r, include = F, results = "hide"}
den201_binary <- load_model_hdf5(here::here("best_models/densenet201_binary/best_densenet201_binary050.h5"))
```


```{r, echo = F, fig.align="center"}
#load model
summary(den201_binary)
```
&nbsp;
&nbsp;

**Small test set**
```{r, echo = F, fig.align="center"}
bindens <- den201_binary %>% evaluate_generator(generator = test_binary, steps = test_binary$n / test_binary$batch_size)
print(bindens)
```
Based on our small test set, we can predict COVID patients in `r label_percent(accuracy = 4)(round(bindens$categorical_accuracy,4))` of the cases. 
&nbsp;
&nbsp;
&nbsp;
&nbsp;


**Large test set**
```{r, echo = F, fig.align="center"}
bindenl <- den201_binary %>% evaluate_generator(generator = large_test_binary, steps = large_test_binary$n / large_test_binary$batch_size)

print(bindenl)
```
When we test our model on the large dataset, the accuracy reaches `r label_percent(accuracy = 4)(round(bindenl$categorical_accuracy,4))`.
&nbsp;

### Multiclass VGG16
Structure of the model :

* VGG16 base
* 2 hidden layers with 100 and 50 nodes respectively
* Final layer with 4 nodes and the softmax activation function
* ReLU activation function in each hidden layer
* No dropout rate
* No $l_1$ regularization penalty
* RMSprop optimizer with a learning rate of 0.0001



We train this model for 30 epochs and we use early stopping with patience = 7. 

```{r, include = F, results = "hide"}
vgg16_mc <- load_model_hdf5(here::here("best_models/vgg16_mc/best_vgg16_mc.h5"))
```


```{r, echo = F, fig.align="center"}
#load model
summary(vgg16_mc)
```
&nbsp;
&nbsp;

**Small test set**

```{r, echo = F, fig.align="center"}
mc16s <- vgg16_mc %>% evaluate_generator(generator = test_mc, steps = test_mc$n / test_mc$batch_size)

print(mc16s)

```
Based on our small test set, we can predict COVID patients in `r label_percent(accuracy = 4)(round(mc16s$categorical_accuracy,4))` of the cases.
&nbsp;
&nbsp;
&nbsp;
&nbsp;

**Large test set**
```{r, echo = F, fig.align="center"}
mc16l <- vgg16_mc %>% evaluate_generator(generator = large_test_mc, steps = large_test_mc$n / large_test_mc$batch_size)

print(mc16l)

```
When we test our model on the large dataset, the accuracy reaches `r label_percent(accuracy = 4)(round(mc16l$categorical_accuracy,4))`.


### Multiclass DenseNet201
We discard this model because the accuracy of the best model after tuning is less than 60%. 

## {-}

## Limitations / Improvements
Based on our two analyses, we think that further improvements could be made. First, X-rays of healthy patients are in fact images of children because we did not find reliable data of adults. This is one of the main limitations of our project. Did the model learn to correctly identify features specific to COVID infection or did it learn to distinguish between adults and children ? The most likely answer is that our model is sensitive to specific features of COVID+ patients. Still, it would be good to have access to healthy adults data to check if this is truly the case. 

Another improvement which could be made is access to more COVID+ images. At the time being, too few images are freely accessible. This issue is not specific to our project because researchers used at most 224 images of infected patients. 

If we had been able to compute the confusion matrix, then we could have further elaborated on sensitivity and specificity. This is even more important in an epidemiological context. Even if we used the validation categorical accuracy and the validation loss as our first and second metrics, the most important criterion besides these is sensitivity. False negatives are much more costly because this would mean undetecting infected people. 

So the next steps would be to collect images of healthy adults, to have more COVID chest X-rays and to use the sensitivity as a metric to improve how efficient our model can be. 


## <strong>References</strong>


